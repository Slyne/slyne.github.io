---
title: 马尔科夫链蒙特卡洛法
description: 快速回顾马尔科夫链蒙特卡洛法的基本知识点~
categories:
- 统计
tags:
- 马尔科夫链
- 蒙特卡洛
---

## 概览
马尔科夫蒙特卡洛法(Markov Chain Monte Carlo, MCMC)经常用在贝叶斯概率模型的推理和学习中,主要是为了解决计算困难的问题。日常中我们会用采样的方法采集样本，进行近似的数值计算，比如计算样本均值，方差，期望。虽然许多常见的概率密度函数(t分布，均匀分布，正态分布..)，我们都可以直接在numpy, scikit-learn中找到，但很多时候，一些概率密度函数，特别是高维的概率密度函数，并不是常见的分布，这个时候我们就需要用到MCMC啦。
在开始马尔科夫蒙特卡洛法之前，我们先简单的介绍一些蒙特卡洛法和马尔科夫链。

## 蒙特卡洛法 Monte Carlo
蒙特卡洛法是比较宽泛的一系列算法的统称(你要想了解以这个赌场自行google)，它的特点是假设概率分布已知，通过重复的随机采样来获得数值结果。比如根据大数定理，我们可以用采样得到的样本计算得到的样本均值来估计总体期望(例子1)。又比如，积分的运算往往可以表示为随机变量在一个概率密度函数分布上的期望(例子2)。

例子1：
假设有随机变量$x$，定义域$X$，其概率密度函数为$p(x)$, f(x)为定义在$X$上的函数，目标是求函数$f(x)$关于密度函数$p(x)$的数学期望$E_{p(x)}[f(x)]$。
蒙特卡洛法根据概率分布$p(x)$独立地抽样$n$个样本$x_1,x_2,.....x_n$,得到近似的$f(x)$期望为:

$$E_{p(x)}[f(x)] \approx \frac{1}{n} \sum_{i=0}^n f(x_i) $$

例子2：
假设我们想要求解$h(x)$在$X$上的积分:

$$\int_{X}h(x)dx$$

我们将$h(x)$分解成一个函数$f(x)$和一个概率密度函数$p(x)$的乘积，进而又将问题转换为求解函数$f(x)$关于密度函数$p(x)$的数学期望$E_{p(x)}[f(x)]$:

$$\int_{X}h(x)dx = \int_{X} \frac{h(x)}{p(x)}p(x)dx = \int_{X}f(x)p(x)= E_{p(x)}[f(x)]$$

这里，$f(x)$表示为$\frac{h(x)}{p(x)}$，则有:

$$\int_{X}h(x)dx = E_{p(x)}[f(x)] \approx \frac{1}{n} \sum_{i=0}^n f(x_i)$$

更一般的，假设我们想要求解$\int_0^{10} x^2dx$，熟悉积分的同学肯定已经知道答案为$\frac{1000}{3}$ (hint: $\frac{1}{3}x^3$)，那么如何用采样的方法来得到这个值呢?

令 $$p(x)=\frac{1}{10} \quad 0< x < 10$$, 那么 $f(x)=10 * x^2$

```python
import random
numSamples=10000
# 在 0-10的均匀分布内采样
samples = [random.uniform(0,10) for _ in range(num_samples)]
f_samples = [10 * sample ** 2 for sample in samples]
result = 1/10000.0 * sum(f_samples)
#>>> result
#333.7766822849899
```

对于复杂的$h(x)$, 这种方法计算起来显然就更加方便啦。(特别是忘记积分怎么算的同学 :speak_no_evil:)

到这里为止，我们简单的介绍了蒙特卡洛方法，但是依旧没有提到要怎么利用复杂的概率密度函数进行采样。接下来我们来看一下**接受-拒绝法(accept-reject sampling method)**，它也是蒙特卡洛法中的一种类型适用于不能直接抽样的情况。

### 接受-拒绝法 ###
假设有一个非常复杂不常见的分布$p(x)$，我们没有现成的工具包可以调用后进行采样，那么我们可以用我们已经有的采样分布比如高斯分布作为**建议分布(proposal distribution)**，用$q(x)$表示，来进行采样，再按照一定的方法来拒绝当前的样本，使得最后得到的样本尽可能的逼近于$p(x)$。

首先我们需要找到一个常数$k$使得$kq(x)$一定大于等于$p(x)$, 也就是如图所示，$p(x)$在$q(x)$下面。接着对$q(x)$进行采样，假设得到的样本为$z_0$。然后我们按照均匀分布在$(0, kq(z_0))$中采样得到$u$。如果$u$落到了图中的灰色区域，则拒绝这次采样，否则接受样本$z_0$。重复这个过程得到一系列的样本$z_0,z_1,...z_n$。

![AcceptReject](https://images2015.cnblogs.com/blog/1042406/201703/1042406-20170327143755811-993574578.png )


在这个过程中，我们可以发现只有当建议分布$q(x)$和复杂分布$p(x)$重合的尽可能多的地方的样本更有可能被接受。那么相反的，如果他们重合部分非常少，那么就会导致拒绝的比例很高，抽样的效率就降低了。很多时候我们时候在高维空间进行采样，所以即使$p(x)$和$q(x)$很接近，两者的差异也可能很大。

我们可以发现接受-拒绝法需要我们提出一个建议分布和常量，而且采样的效率也不高，那么我们就需要一个更一般的方法，就是我们的马尔科夫蒙特卡洛法啦。不过MCMC依旧有个问题, 它的抽样样本不是独立的。到了Gibbs Sampling的部分，我们可以看到它做了一些小trick，来假装使得样本独立。

## 马尔科夫链
马尔科夫链的定义和概念相信大家都很熟悉了(不熟悉的请google)。在这里，我们回顾一下几个重要的知识点:

### 平稳分布
**平稳分布** 设有马尔科夫链 $X=\{X_0, X_1, ..., X_t, ...\}$, 其状态空间为 $S$, 转移概率矩阵为 $P=(p_{ij})$, 如果存在状态空间$S$上的一个分布

$$ \pi= \begin{bmatrix} \pi_1 \\ \pi_2 \\\vdots \end{bmatrix} $$

使得 $\pi=P\pi$

则称$\pi$为马尔科夫链$X=\{X_0, X_1, ..., X_t, ...\}$的平稳分布

我们可以理解为，当一个初始分布为该马尔科夫链的平稳分布的时候，接下来的任何转移操作之后的结果分布依然是这个平稳分布。注意，马尔科夫链可能存在唯一平稳分布，无穷多个平稳分布，或者不存在平稳分布。

其它定理:
1. 不可约且非周期的有限状态马尔科夫链，有唯一平稳分布存在。

2. 不可约、非周期且正常返的马尔科夫链，有唯一平稳分布存在。

其中，不可约和正常返大家请自行查阅相关定义。 直观上可以理解为，任何两个状态都是连通的，即从任意一个状态跳转到其它任意状态的概率值大于零。

### 遍历定理
**遍历定理** 设有马尔科夫链 $X=\{X_0, X_1, \dots, X_t, \dots \}$, 其状态空间为 $S$, 若马尔科夫链$X$是不可约、非周期且正常返的，则该马尔科夫链有唯一平稳分布$ \pi= \begin{pmatrix} \pi_1, \pi_2, \dots \end{pmatrix}^T $, 且转移概率的极限分布是马尔科夫链的平稳分布。

$$\lim_{t \to +\infty} P(X_t=i|X_0=j)=\pi_i  \quad i=1,2,\dots; j=1,2,\dots$$

直观上,$P$最后会收敛成这个样子:

$$ \lim_{t \to +\infty} P^n= 
\begin{pmatrix} 
\pi_1 & \pi_1 & \dots & \pi_1 & \dots \\
\pi_2 & \pi_2 & \dots & \pi_2 & \dots \\
\dots & \dots & \dots & \dots & \dots \\
\pi_j & \pi_j   & \dots  & \pi_j & \dots \\
\dots & \dots & \dots & \dots & \dots
 \end{pmatrix} $$

我们可以理解为，当时间趋于无穷时，马尔科夫链的状态分布趋近于平稳分布。
另外，无论初始的分布$\pi'$是什么，经过了$n$次转移后, 即$P^n\pi'$, 最后都会收敛到它的平稳分布$\pi$ (原理待补充)。结合这两点，我们就可以用马尔科夫链进行采样。

首先我们随机一个样本$x_0$，基于条件概率(转移概率)$P(x\|x_0)$ 采样$x_1$，因为我们需要转移一定次数后才会收敛到我们的平稳分布，所以比如我们设定了m次迭代后为平稳分布，那么 $(x_m, x_{m+1}, \dots)$ 即为平稳分布对应的样本集。

但是，要怎么确定平稳分布$\pi$(我们希望采样的复杂分布)的马尔科夫链状态转移矩阵或者转移核$P$呢？
在开始MCMC采样之前我们还需要回顾两个知识点: 可逆马尔科夫链和平衡细致方程。


## Metropolis-Hastings

## Gibbs Sampling

## Reference
[1] 李航. 统计学习方法第二版[J]. 2019.

[2] https://www.cnblogs.com/pinard/p/6625739.html

[3] 



